{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_processing import *\n",
    "from const import ROOT\n",
    "from const import *\n",
    "from post_processing import train_file_list, test_file_list\n",
    "import pickle\n",
    "def rle_decode(rle_mask,size):\n",
    "    '''\n",
    "    rle_mask: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = rle_mask.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(size*size, dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(size,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = rle_decode(\"1 605 607 99 708 99 809 98 910 97 1011 97 1112 96 1213 95 1314 95 1415 94 1516 94 1617 94 1718 93 1819 93 1920 93 2021 93 2122 93 2223 94 2324 93 2425 93 2526 92 2627 92 2728 91 2829 90 2930 89 3031 89 3132 90 3233 91 3334 93 3435 95 3536 96 3637 95 3738 95 3839 94 3940 92 4041 91 4142 90 4243 89 4344 88 4445 87 4546 87 4647 86 4748 85 4849 85 4950 84 5051 83 5152 82 5253 82 5354 81 5455 81 5556 80 5657 80 5758 80 5859 79 5960 78 6061 78 6162 77 6263 77 6364 77 6465 77 6566 78 6667 78 6768 79 6869 79 6970 79 7071 79 7172 79 7273 80 7374 80 7475 81 7576 81 7677 81 7778 81 7879 81 7980 81 8081 81 8182 81 8283 81 8384 81 8485 81 8586 81 8687 81 8788 81 8889 82 8990 82 9091 82 9192 82 9293 82 9394 83 9495 83 9596 84 9697 86 9798 88 9899 91 10000 93 10101 94\",101)\n",
    "Image.fromarray(mask*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 101, 101\n",
    "\n",
    "if height % 32 == 0:\n",
    "    y_min_pad = 0\n",
    "    y_max_pad = 0\n",
    "else:\n",
    "    y_pad = 32 - height % 32\n",
    "    y_min_pad = int(y_pad / 2)\n",
    "    y_max_pad = y_pad - y_min_pad\n",
    "\n",
    "if width % 32 == 0:\n",
    "    x_min_pad = 0\n",
    "    x_max_pad = 0\n",
    "else:\n",
    "    x_pad = 32 - width % 32\n",
    "    x_min_pad = int(x_pad / 2)\n",
    "    x_max_pad = x_pad - x_min_pad\n",
    "print((y_min_pad,y_max_pad, x_min_pad, x_max_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = pickle.load( open( \"ocnet_all_sigmoids.p\", \"rb\" ) )\n",
    "arr2 = pickle.load( open( \"resnet34_all_sigmoids.p\", \"rb\" ) )\n",
    "import cv2\n",
    "\n",
    "arr2 = arr2[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]\n",
    "\n",
    "arr1 = arr1[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]\n",
    "\n",
    "arr = (arr1+arr2)/2\n",
    "#arr= arr>0.5\n",
    "dicts={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr1.mean())\n",
    "print(arr2.mean())\n",
    "print(arr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3 = arr>0.38\n",
    "dicts={}\n",
    "arr1.shape\n",
    "mean = 0.5*np.ones((101,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage=[]\n",
    "for i in tqdm(range(arr3.shape[0])):\n",
    "    mask=arr3[i,:,:]\n",
    "    coverage.append(arr3[i,:,:].sum()/(101*101))\n",
    "    dicts[i]=np.array((mask-mean)**2).mean()\n",
    "    #im = Image.fromarray(mask*255)\n",
    "    #im.show()\n",
    "    #break\n",
    "dicts=np.array(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(coverage, bins=50)  # arguments are passed to np.histogram\n",
    "plt.title(\"higher means better\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=0\n",
    "for i in coverage:\n",
    "    if i ==0: ct=ct+1\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"256_arith_mean.csv\")\n",
    "ct=0\n",
    "for i in tqdm(range(len(test_file_list))):\n",
    "    #print(row[1][\"rle_mask\"] is float)\n",
    "    try:\n",
    "        s=0\n",
    "        if coverage[i]==0:\n",
    "            #print(\"s\")\n",
    "            s=s+1\n",
    "        #print(s)\n",
    "        if s>0: \n",
    "            ct=ct+1\n",
    "            df2.loc[df2['id'] == df2.iloc[i]['id'],'rle_mask']=' '.join(map(str, \"\"))        \n",
    "    except ValueError:\n",
    "        a=1\n",
    "print(\"setting {} masks to empty\".format(ct))\n",
    "\n",
    "ct=0\n",
    "for i in tqdm(range(len(df2))):\n",
    "    #print(row[1][\"rle_mask\"] is float)\n",
    "    try:\n",
    "        s=0\n",
    "        if type(df2.iloc[i][\"rle_mask\"]) is float or df2.iloc[i][\"rle_mask\"] == '' :\n",
    "            #print(\"s\")\n",
    "            s=s+1\n",
    "        #print(s)\n",
    "        if s>0: \n",
    "            ct=ct+1\n",
    "            #df2.loc[df2['id'] == df.iloc[i]['id'],'rle_mask']=' '.join(map(str, \"\"))        \n",
    "    except ValueError:\n",
    "        a=1\n",
    "print(\"{} empty masks in total\".format(ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"256_60models_new038.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"256_60models_new038.csv\")\n",
    "ct=0\n",
    "for i in tqdm(range(len(test_file_list))):\n",
    "    #print(row[1][\"rle_mask\"] is float)\n",
    "    try:\n",
    "        s=0\n",
    "        if coverage[i]==0:\n",
    "            #print(\"s\")\n",
    "            s=s+1\n",
    "        #print(s)\n",
    "        if s>0: \n",
    "            ct=ct+1\n",
    "            df2.loc[df2['id'] == df2.iloc[i]['id'],'rle_mask']=' '.join(map(str, \"1 1\"))\n",
    "        else:\n",
    "            df2.loc[df2['id'] == df2.iloc[i]['id'],'rle_mask']=' '.join(map(str, \"\"))\n",
    "    except ValueError:\n",
    "        a=1\n",
    "print(\"setting {} masks to empty\".format(ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"256_50models_038.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"256_arith_mean_smoothed_only.csv\") #7331\n",
    "#df2 = pd.read_csv(\"0875_baseline.csv\") #7617\n",
    "ct=0\n",
    "for i in tqdm(range(len(df2))):\n",
    "    #print(row[1][\"rle_mask\"] is float)\n",
    "    try:\n",
    "        s=0\n",
    "        if type(df2.iloc[i][\"rle_mask\"]) is float or df2.iloc[i][\"rle_mask\"] == '' :\n",
    "            #print(\"s\")\n",
    "            s=s+1\n",
    "        #print(s)\n",
    "        if s>0: \n",
    "            ct=ct+1\n",
    "            #df2.loc[df2['id'] == df.iloc[i]['id'],'rle_mask']=' '.join(map(str, \"\"))        \n",
    "    except ValueError:\n",
    "        a=1\n",
    "print(\"{} empty masks in total\".format(ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong={}\n",
    "a=dicts.mean()+2*dicts.std()\n",
    "print(a)\n",
    "for i in tqdm(range(arr.shape[0])):\n",
    "    if dicts[i]<a and arr[i,:,:].sum()<0.9 and arr[i,:,:].std()>0.1:\n",
    "        strong[i]=dicts[i]\n",
    "print(\"num of strong examples \",len(weak))\n",
    "#max(weak.values())\n",
    "for name, age in strong.items():    # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "    if age == min(strong.values()):\n",
    "        print(name)\n",
    "pickle.dump(list(weak.keys()),open(\"256_strong_samples.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=9821\n",
    "for j in tqdm(range(arr.shape[0])):\n",
    "    mask=arr[i,:,:]\n",
    "    #print(mask)\n",
    "    #dicts.append(np.array((mask-mean)**2).mean())\n",
    "    im = Image.fromarray(mask*255)\n",
    "    im.show()\n",
    "    \n",
    "    mask2=arr2[i,:,:]\n",
    "    #print(mask)\n",
    "    #dicts.append(np.array((mask-mean)**2).mean())\n",
    "    im2 = Image.fromarray(mask2*255)\n",
    "    im2.show()\n",
    "    \n",
    "    mask3=arr1[i,:,:]\n",
    "    #print(mask)\n",
    "    #dicts.append(np.array((mask-mean)**2).mean())\n",
    "    im3 = Image.fromarray(mask3*255)\n",
    "    im3.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"256_45models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2015):\n",
    "    row = df.iloc[i]\n",
    "    #print(row['rle_mask'])\n",
    "    mask=rle_decode(row['rle_mask'],size=101)\n",
    "    im = Image.fromarray(mask*255)\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(ROOT, 'test')\n",
    "test_file_list = glob.glob(os.path.join(test_path, 'images', '*.png'))\n",
    "test_file_list = [f.split('/')[-1].split('.')[0] for f in test_file_list]\n",
    "train_path = os.path.join(ROOT, 'train')\n",
    "train_file_list = glob.glob(os.path.join(train_path, 'images', '*.png'))\n",
    "train_file_list = [f.split('/')[-1].split('.')[0] for f in train_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx=500\n",
    "img = Image.open(ROOT+'/test/images/'+test_file_list[indx]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(ROOT+\"/depths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageStat\n",
    "import math\n",
    "stat = ImageStat.Stat(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = (math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2)) for r,g,b in img.getdata())\n",
    "sum(gs)/stat.count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths.loc[depths['id'] == test_file_list[indx]]['z'].values[0]\n",
    "brightness=[]\n",
    "depth=[]\n",
    "coverage=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(train_file_list))):\n",
    "    img = Image.open(ROOT+'/train/images/'+train_file_list[i]+'.png')\n",
    "    mask = np.array(Image.open(ROOT+'/train/masks/'+train_file_list[i]+'.png'))\n",
    "    coverage.append(mask.sum()/101*101)\n",
    "    stat = ImageStat.Stat(img)\n",
    "    gs = (math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2)) for r,g,b in img.getdata())\n",
    "    brightness.append(sum(gs)/stat.count[0])\n",
    "    depth.append(depths.loc[depths['id'] == train_file_list[i]]['z'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths=np.array([depth]).reshape(-1,1)\n",
    "coverages=np.array([coverage]).reshape(-1,1)\n",
    "brightnesses=np.array([brightness]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_iters = 5\n",
    "preds_buf = []\n",
    "err_buf = []\n",
    "for i in range(n_iters): \n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(depths,coverages, test_size=0.10, random_state=i)\n",
    "    \n",
    "    x_train=scaler.fit_transform(x_train)\n",
    "    y_train=scaler.fit_transform(y_train)\n",
    "    \n",
    "    x_valid=scaler.fit_transform(x_valid)\n",
    "    y_valid=scaler.fit_transform(y_valid)\n",
    "    lgb_train = lgb.Dataset(x_train, y_train.ravel())\n",
    "    lgb_eval = lgb.Dataset(x_valid, y_valid.ravel(), reference=lgb_train)\n",
    "\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'auc'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    print('Start training...')\n",
    "    # train\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=20,\n",
    "                    valid_sets=lgb_eval)\n",
    "\n",
    "    preds = gbm.predict(x_valid)\n",
    "    err = rmsle(np.exp(y_valid), preds)\n",
    "    err_buf.append(err)\n",
    "    print('RMSLE = ' + str(err))\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    preds = np.exp(preds)\n",
    "    preds_buf.append(preds)\n",
    "\n",
    "print('Mean RMSLE = ' + str(np.mean(err_buf)) + ' +/- ' + str(np.std(err_buf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT='/home/alexanderliao/data/Kaggle/competitions/tgs-salt-identification-challenge/'\n",
    "train_path = os.path.join(ROOT, 'train')\n",
    "train_file_list = glob.glob(os.path.join(train_path, 'images', '*.png'))\n",
    "train_file_list = [f.split('/')[-1].split('.')[0] for f in train_file_list]\n",
    "test_path = os.path.join(ROOT, 'test')\n",
    "test_file_list = glob.glob(os.path.join(test_path, 'images', '*.png'))\n",
    "test_file_list = [f.split('/')[-1].split('.')[0] for f in test_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for file in train_file_list:\n",
    "    if os.path.getsize(ROOT+'train/images/'+file+'.png')==107:\n",
    "        i=i+1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for file in test_file_list:\n",
    "    if os.path.getsize(ROOT+'test/images/'+file+'.png')==107:\n",
    "        i=i+1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1562/4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7614/18000-0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.61-0.032)*0.855+0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100-39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
